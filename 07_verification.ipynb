{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-fisher",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_default_export verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm import tqdm\n",
    "from drt.environment import DataIntakeEnv\n",
    "import drt.data_model as dm\n",
    "import drt.utils as utils\n",
    "from drt.utils import Data_Groups_Type\n",
    "\n",
    "\n",
    "def check_datagroup(env:DataIntakeEnv,\n",
    "                    data_group_type: Data_Groups_Type,\n",
    "                    light:bool = True) -> None:\n",
    "    \"\"\"\n",
    "    A function to check data folders and determine if the data folder registration\n",
    "    has been properly filled out. It checks for the following things:\n",
    "        - Have all the data groups in the folder been registered?\n",
    "        - Were any data groups modified since the last check?\n",
    "        - Have all the data groups in the folder had their descriptions and origin updated?\n",
    "        - Warning if a registered delivery is missing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : DataIntakeEnv\n",
    "\n",
    "    data_group_type : Data_Groups_Type\n",
    "        Which type of Data Folder are we checking\n",
    "        \n",
    "    light : bool, optional\n",
    "        Skip file hashing in the comparison\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    TODO\n",
    "    [>>> example_usage_of_module in pydoctest]\n",
    "    \"\"\"\n",
    "    if data_group_type == dm.Delivery:\n",
    "        data_folder = env.delivery_folder\n",
    "        err_str = 'DLV'\n",
    "    elif data_group_type == dm.Raw_Data:\n",
    "        data_folder = env.raw_data_folder\n",
    "        err_str = 'RAW'\n",
    "    elif data_group_type == dm.Dataset:\n",
    "        data_folder = env.dataset_folder\n",
    "        err_str = 'DAT'\n",
    "    else:\n",
    "        raise TypeError\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    # Collect the deliveries in the delivery folder\n",
    "    if data_group_type == dm.Delivery:\n",
    "        data_groups = [\n",
    "            fil\n",
    "            for fil in data_folder.iterdir()\n",
    "            if fil.is_dir() and not fil.name.startswith(\".\")\n",
    "        ]\n",
    "    else:\n",
    "        data_groups = [\n",
    "            fil\n",
    "            for fil in data_folder.iterdir()\n",
    "            if fil.is_dir() and not fil.name.startswith(\".\") and not fil.name.lower().startswith('in_progresss')\n",
    "        ]\n",
    "    \n",
    "    # Loop through all the directories in the deliveries folder to process\n",
    "    for data_group in tqdm(data_groups, unit=\"data group\", leave=False):\n",
    "\n",
    "        # Get file sizes, last modified dates, and names to count,\n",
    "        # sum size, and if light is false, hash the file data provided\n",
    "        data = None\n",
    "        try:\n",
    "            data = utils.process_data_group(data_group, data_group_type, light)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"[{err_str}] Registered data missing files or empty folder at {data_group}\")\n",
    "\n",
    "        # Get the delivery record\n",
    "        record = env.session.query(data_group_type).filter_by(name=data_group.name).first()\n",
    "\n",
    "        # Check to see if this delivery has data associated with it. It should have at least 1\n",
    "        if not record:\n",
    "            errors.append(f\"[{err_str}] No Data registered for: {data_group.name}\")\n",
    "        elif data:\n",
    "            if data['group_last_modified'] > record.last_update:\n",
    "                errors.append(f\"[{err_str}] Data in {data_group.name} changed since registration\")\n",
    "            ## compare the record to the calculated data\n",
    "            if not data['size'] == record.size:\n",
    "                errors.append(f\"[{err_str}] Size in {data_group.name} changed since registration\") \n",
    "            if not data['num_files'] == record.num_files:\n",
    "                errors.append(f\"[{err_str}] Number of files in {data_group.name} changed since registration\")     \n",
    "            if not light:\n",
    "                if not data['group_hash'] == record.group_hash:\n",
    "                    errors.append(f\"[{err_str}] Hash of {data_group.name} changed since registration\") \n",
    "            if record.description is None:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} missing description\") \n",
    "\n",
    "            if data_group_type == dm.Delivery and record.delivery_source is None:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} missing source\") \n",
    "            if data_group_type == dm.Delivery and record.date_received is None:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} missing delivery date\") \n",
    "            if data_group_type == dm.Delivery and len(record.extracted_data) == 0:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} no data extracted\") \n",
    "\n",
    "            if data_group_type == dm.Raw_Data and record.source is None:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} missing source\")\n",
    "            if data_group_type == dm.Raw_Data and record.statistics_report is None:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} missing statistics report\")\n",
    "\n",
    "\n",
    "            if data_group_type == dm.Dataset and record.dataset_report is None:\n",
    "                errors.append(f\"[{err_str}] {data_group.name} missing dataset data sheet\")\n",
    "            \n",
    "    # retrieve any deliveries that are registered but have no data\n",
    "    registered = env.session.query(data_group_type).filter(data_group_type.name.notin_([f.name for f in data_groups])).all()\n",
    "    for item in registered:\n",
    "        errors.append(f\"[{err_str}] {item.name} registered but no data\") \n",
    "\n",
    "    ## TODO WRITE REPORT OUTPUT HERE\n",
    "    print(\"\\n\".join(errors))\n",
    "\n",
    "    return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drt",
   "language": "python",
   "name": "drt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
