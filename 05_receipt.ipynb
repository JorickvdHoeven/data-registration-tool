{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-certificate",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "#default_exp receipt\n",
    "#default_cls_lvl 3\n",
    "from nbdev import *\n",
    "from drt.receipt import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "from pathlib import Path\n",
    "import drt.data_model as dm\n",
    "import re\n",
    "from typing import Union\n",
    "from drt.environment import DataIntakeEnv\n",
    "from dateutil import parser\n",
    "from sqlalchemy import inspect\n",
    "from typing import Union\n",
    "from drt.utils import Data_Groups_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-cleaners",
   "metadata": {},
   "source": [
    "# Receipt\n",
    "\n",
    "> Generate ReST formatted data stubs for each data element which can be used as a base for a statically generated site and/or updated by users to correct information. In particular, these receipts are where analysts will be able to enter details about the data elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sync_data_folder(env: DataIntakeEnv, data_group_type: Data_Groups_Type):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    env : DataIntakeEnv\n",
    "        [description]\n",
    "\n",
    "    data_group_type : Data_Groups_Type\n",
    "        [description]\n",
    "\n",
    "    ##### Raises  \n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "    if data_group_type == dm.Delivery:\n",
    "        data_folder = env.delivery_folder\n",
    "    elif data_group_type == dm.Raw_Data:\n",
    "        data_folder = env.raw_data_folder\n",
    "    elif data_group_type == dm.Dataset:\n",
    "        data_folder = env.dataset_folder\n",
    "    else:\n",
    "        raise TypeError(data_group_type)\n",
    "\n",
    "    for data_group in data_folder.iterdir():\n",
    "        sync_data_group(env, data_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sync_data_group(env: DataIntakeEnv, data_group: Path):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    env : [type]\n",
    "        [description]\n",
    "\n",
    "    data_group : Path\n",
    "        [description]\n",
    "\n",
    "    data_group_type : str\n",
    "        [description]\n",
    "\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data_group_type = env.get_group_type_from_path(data_group)\n",
    "\n",
    "    if data_group.is_dir() and (data_group / 'receipt.rst').exists():\n",
    "        record = env.session.query(data_group_type).filter_by(name=data_group.name).first()\n",
    "        if record:\n",
    "            sync_receipt(env, (data_group / 'receipt.rst'), record)\n",
    "        else:\n",
    "            print(f'[!] record not found for {data_group.name}, can''t sync')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sync_receipt(env: DataIntakeEnv, receipt_path: Path, data_group: Data_Groups_Type):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters \n",
    "    env : DataIntakeEnv\n",
    "        [description]\n",
    "\n",
    "    receipt_path : Path\n",
    "        [description]\n",
    "\n",
    "    data_group : Union[dm.Dataset, dm.Delivery, dm.Raw_Data]\n",
    "        [description]\n",
    "\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    receipt_data = parse_receipt(env, receipt_path)\n",
    "\n",
    "    for k, v in receipt_data.items():\n",
    "        if k == 'description':\n",
    "            data_group.description = v\n",
    "        elif k == 'date_received':\n",
    "            data_group.date_received = v\n",
    "        elif k == 'delivery_source':\n",
    "            data_group.delivery_source = v\n",
    "        elif k == 'statistics_report':\n",
    "            data_group.statistics_report = v\n",
    "        elif k == 'dataset_report':\n",
    "            data_group.dataset_report = v\n",
    "\n",
    "    env.session.commit()\n",
    "\n",
    "    # for each column compare text repr with data\n",
    "    # cols have different masters:\n",
    "    #  [[done]] Description, Source, Received date, are file master\n",
    "    #  Tags are file master\n",
    "    #  [[done]] System fields are db master\n",
    "    #  links are outer join of file and db\n",
    "\n",
    "    # update DB\n",
    "    print(f\"Writing receipt to {receipt_path.parent}\")\n",
    "    write_receipt(env, receipt_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def write_receipt(env: DataIntakeEnv, folder: Path):\n",
    "    \"\"\"\n",
    "    Create a receipt for a data group based on information from the sqlite database.\n",
    "\n",
    "    ##### Parameters \n",
    "    env : DataIntakeEnv\n",
    "        The data registration environment\n",
    "\n",
    "    folder : Path\n",
    "        Folder path to the Data Group to create a receipt for.\n",
    "\n",
    "    group_type : str\n",
    "        What type of data group is this data element.\n",
    "\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        Raised if the data group type is not correct\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dg = env.get_group_type_from_path(folder)\n",
    "\n",
    "    # Get folder info from database\n",
    "    folder_info = env.session.query(dg).filter_by(name=folder.name).first()\n",
    "\n",
    "    # Write data to folder using data model serialization\n",
    "    with open((folder / 'receipt.rst'), mode='wt') as f:\n",
    "        try:\n",
    "            f.write(folder_info.document())\n",
    "        except Exception as e:\n",
    "            print(\"Registering Failed\")\n",
    "            print(folder.name, folder_info, dg)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_receipt(env: DataIntakeEnv, receipt_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    receipt_path : Path\n",
    "        [description]\n",
    "\n",
    "    group_type : str\n",
    "        [description]\n",
    "\n",
    "\n",
    "    ##### Returns\n",
    "    dict\n",
    "        [description]\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "    text = receipt_path.read_text()\n",
    "\n",
    "    group_type = env.get_group_type_from_path(receipt_path.parent)\n",
    "\n",
    "    patterns = dict()\n",
    "    data = dict()\n",
    "\n",
    "    if group_type == dm.Delivery:\n",
    "        # extract data with these regexes\n",
    "        patterns['description'] = re.compile(r'Description:\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        patterns['date_received'] = re.compile(r'\\n:Date Received: (.+)$', re.MULTILINE)\n",
    "        patterns['delivery_source'] = re.compile(r'\\n:Received from: (.+)$', re.MULTILINE)\n",
    "    elif group_type == dm.Raw_Data:\n",
    "        # extract data with these regexes\n",
    "        patterns['description'] = re.compile(r'Description:\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        patterns['statistics_report'] = re.compile(r'Report\\n-+\\n(.*?)\\n.*', re.MULTILINE | re.DOTALL)\n",
    "        pass\n",
    "    elif group_type == dm.Dataset:\n",
    "        # extract data with these regexes\n",
    "        patterns['description'] = re.compile(r'Description:\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        patterns['dataset_report'] = re.compile(r'Report\\n-+\\n(.*?)\\n.*', re.MULTILINE | re.DOTALL)\n",
    "        pass\n",
    "    else:\n",
    "        raise TypeError\n",
    "\n",
    "    for k, v in patterns.items():\n",
    "        res = re.search(v, text)\n",
    "        if res:\n",
    "            data[k] = res.group(1)\n",
    "            if data[k] == 'None':\n",
    "                data[k] = None\n",
    "            if 'date' in k and not data[k] is None:\n",
    "                data[k] = parser.parse(data[k])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dummy HTML Report'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "text = '''\n",
    "\n",
    "\n",
    "File Metadata\n",
    "-------------\n",
    ":Files Last Changed: 2021-02-10 20:32:52.637435\n",
    ":File Size: 1244762\n",
    ":Number of Files: 3\n",
    ":Hash: 975bd61edb1adec7b61b8fb459de04e775d286bcc5cd19a4be67c74c04044e46\n",
    "\n",
    "Report\n",
    "------\n",
    "Dummy HTML Report\n",
    "\n",
    "\n",
    "'''\n",
    "re.search(r'Report\\n-+\\n(.*?)\\n.*',text,  re.MULTILINE | re.DOTALL)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_tests.ipynb.\n",
      "Converted 01_cli.ipynb.\n",
      "Converted 02_create_environment.ipynb.\n",
      "Converted 03_data_model.ipynb.\n",
      "Converted 04_environment.ipynb.\n",
      "Converted 05_receipt.ipynb.\n",
      "Converted 06_registration.ipynb.\n",
      "Converted 07_verification.ipynb.\n",
      "Converted 99_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of drt.data_model failed: Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 292, in update_class\n",
      "    if (old_obj == new_obj) is True:\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/sqlalchemy/sql/operators.py\", line 365, in __eq__\n",
      "    return self.operate(eq, other)\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/sqlalchemy/orm/attributes.py\", line 226, in operate\n",
      "    return op(self.comparator, *other, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/drt/lib/python3.8/site-packages/sqlalchemy/orm/relationships.py\", line 1262, in __eq__\n",
      "    raise sa_exc.InvalidRequestError(\n",
      "sqlalchemy.exc.InvalidRequestError: Can't compare a collection to an object or collection; use contains() to test for membership.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-adapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-timer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-syndrome",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drt",
   "language": "python",
   "name": "drt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
