{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "#default_exp receipt\n",
    "#default_cls_lvl 3\n",
    "from nbdev import *\n",
    "from drt.receipt import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "from pathlib import Path\n",
    "import drt.data_model as dm\n",
    "import re\n",
    "from typing import Union\n",
    "from drt.environment import DataIntakeEnv\n",
    "from dateutil import parser\n",
    "from sqlalchemy import inspect\n",
    "from typing import Union\n",
    "from drt.utils import Data_Groups_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receipt\n",
    "\n",
    "> Generate ReST formatted data stubs for each data element which can be used as a base for a statically generated site and/or updated by users to correct information. In particular, these receipts are where analysts will be able to enter details about the data elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sync_data_folder(env: DataIntakeEnv, data_group_type: Data_Groups_Type):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    env : DataIntakeEnv\n",
    "        [description]\n",
    "\n",
    "    data_group_type : Data_Groups_Type\n",
    "        [description]\n",
    "\n",
    "    ##### Raises  \n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "    if data_group_type == dm.Delivery:\n",
    "        data_folder = env.delivery_folder\n",
    "    elif data_group_type == dm.Raw_Data:\n",
    "        data_folder = env.raw_data_folder\n",
    "    elif data_group_type == dm.Dataset:\n",
    "        data_folder = env.dataset_folder\n",
    "    else:\n",
    "        raise TypeError(data_group_type)\n",
    "\n",
    "    for data_group in data_folder.iterdir():\n",
    "        sync_data_group(env, data_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sync_data_group(env: DataIntakeEnv, data_group: Path):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    env : [type]\n",
    "        [description]\n",
    "\n",
    "    data_group : Path\n",
    "        [description]\n",
    "\n",
    "    data_group_type : str\n",
    "        [description]\n",
    "\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data_group_type = env.get_group_type_from_path(data_group)\n",
    "\n",
    "    if data_group.is_dir() and (data_group / 'receipt.rst').exists():\n",
    "        record = env.session.query(data_group_type).filter_by(name=data_group.name).first()\n",
    "        if record:\n",
    "            sync_receipt(env, (data_group / 'receipt.rst'), record)\n",
    "        else:\n",
    "            print(f'[!] record not found for {data_group.name}, can''t sync')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sync_receipt(env: DataIntakeEnv, receipt_path: Path, data_group: Data_Groups_Type):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters \n",
    "    env : DataIntakeEnv\n",
    "        [description]\n",
    "\n",
    "    receipt_path : Path\n",
    "        [description]\n",
    "\n",
    "    data_group : Union[dm.Dataset, dm.Delivery, dm.Raw_Data]\n",
    "        [description]\n",
    "\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    receipt_data = parse_receipt(env, receipt_path)\n",
    "\n",
    "    for k, v in receipt_data.items():\n",
    "        if k == 'description':\n",
    "            data_group.description = v\n",
    "        elif k == 'date_received':\n",
    "            data_group.date_received = v\n",
    "        elif k == 'delivery_source':\n",
    "            data_group.delivery_source = v\n",
    "\n",
    "    env.session.commit()\n",
    "\n",
    "    # for each column compare text repr with data\n",
    "    # cols have different masters:\n",
    "    #  [[done]] Description, Source, Received date, are file master\n",
    "    #  Tags are file master\n",
    "    #  [[done]] System fields are db master\n",
    "    #  links are outer join of file and db\n",
    "\n",
    "    # update DB\n",
    "    print(f\"Writing receipt to {receipt_path.parent}\")\n",
    "    write_receipt(env, receipt_path.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def write_receipt(env: DataIntakeEnv, folder: Path):\n",
    "    \"\"\"\n",
    "    Create a receipt for a data group based on information from the sqlite database.\n",
    "\n",
    "    ##### Parameters \n",
    "    env : DataIntakeEnv\n",
    "        The data registration environment\n",
    "\n",
    "    folder : Path\n",
    "        Folder path to the Data Group to create a receipt for.\n",
    "\n",
    "    group_type : str\n",
    "        What type of data group is this data element.\n",
    "\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        Raised if the data group type is not correct\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dg = env.get_group_type_from_path(folder)\n",
    "\n",
    "    # Get folder info from database\n",
    "    folder_info = env.session.query(dg).filter_by(name=folder.name).first()\n",
    "\n",
    "    # Write data to folder using data model serialization\n",
    "    with open((folder / 'receipt.rst'), mode='wt') as f:\n",
    "        try:\n",
    "            f.write(folder_info.document())\n",
    "        except Exception as e:\n",
    "            print(\"Registering Failed\")\n",
    "            print(folder.name, folder_info, dg)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_receipt(env: DataIntakeEnv, receipt_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    receipt_path : Path\n",
    "        [description]\n",
    "\n",
    "    group_type : str\n",
    "        [description]\n",
    "\n",
    "\n",
    "    ##### Returns\n",
    "    dict\n",
    "        [description]\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "    text = receipt_path.read_text()\n",
    "\n",
    "    group_type = env.get_group_type_from_path(receipt_path.parent)\n",
    "\n",
    "    patterns = dict()\n",
    "    data = dict()\n",
    "\n",
    "    if group_type == dm.Delivery:\n",
    "        # extract data with these regexes\n",
    "        patterns['description'] = re.compile(r'Description:\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        patterns['date_received'] = re.compile(r'\\n:Date Received: (.+)$', re.MULTILINE)\n",
    "        patterns['delivery_source'] = re.compile(r'\\n:Received from: (.+)$', re.MULTILINE)\n",
    "    elif group_type == dm.Raw_Data:\n",
    "        # extract data with these regexes\n",
    "        patterns['description'] = re.compile(r'Description:\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        patterns['statistics_report'] = re.compile(r'Report\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        pass\n",
    "    elif group_type == dm.Dataset:\n",
    "        # extract data with these regexes\n",
    "        patterns['description'] = re.compile(r'Description:\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        patterns['datastet_report'] = re.compile(r'Report\\n-+\\n(.*?)\\n+[^\\n]+\\n-+\\n', re.MULTILINE | re.DOTALL)\n",
    "        pass\n",
    "    else:\n",
    "        raise TypeError\n",
    "\n",
    "    for k, v in patterns.items():\n",
    "        res = re.search(v, text)\n",
    "        if res:\n",
    "            data[k] = res.group(1)\n",
    "            if data[k] == 'None':\n",
    "                data[k] = None\n",
    "            if 'date' in k and not data[k] is None:\n",
    "                data[k] = parser.parse(data[k])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_cli.ipynb.\n",
      "Converted 02_create_environment.ipynb.\n",
      "Converted 03_data_model.ipynb.\n",
      "Converted 04_environment.ipynb.\n",
      "Converted 05_receipt.ipynb.\n",
      "Converted 06_registration.ipynb.\n",
      "Converted 07_verification.ipynb.\n",
      "Converted 99_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drt",
   "language": "python",
   "name": "drt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
