{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-slovakia",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to drt.cli,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "%nbdev_default_export cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from drt.environment import DataIntakeEnv\n",
    "from drt.create_environment import create_environment\n",
    "from drt.registration import register_all\n",
    "from drt.verification import check_datagroup\n",
    "from drt.receipt import sync_data_folder\n",
    "import drt.data_model as dm\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    parser = argparse.ArgumentParser(description='Manage the data intake process.')\n",
    "    subparsers = parser.add_subparsers(dest='mode')\n",
    "\n",
    "    verify = subparsers.add_parser('verify', help='Verify an existing data intake folder')\n",
    "    verify.add_argument('config_file', metavar='config_path', type=str, nargs='?',\n",
    "                        default='.config/config.ini',\n",
    "                        help='the path of the configuration file')\n",
    "    verify.add_argument('-d', '--deep', action='store_true',\n",
    "                        help='''calculate hashes when performing verification''')\n",
    "\n",
    "    register = subparsers.add_parser('register', help='Register new deliveries and datasets')\n",
    "    register.add_argument('config_file', metavar='config_path', type=str, nargs='?',\n",
    "                          default='.config/config.ini',\n",
    "                          help='the path of the configuration file')\n",
    "    register.add_argument('-f', '--force', action='store_true',\n",
    "                          help='''force the tool to re-calulate and re-register the system values''')\n",
    "\n",
    "    create = subparsers.add_parser('create', help='Create a new data intake folder')\n",
    "    create.add_argument('location', type=str, action='store', nargs='?', const='.',\n",
    "                        help='create a new environment in the provided path')\n",
    "\n",
    "    document = subparsers.add_parser('document',\n",
    "                                     help='Build documentation based on information in db and provided by analysts')\n",
    "    document.add_argument('config_file', metavar='config_path', type=str, nargs='?',\n",
    "                          default='.config/config.ini',\n",
    "                          help='the path of the configuration file')\n",
    "    document.add_argument('-f', '--force', action='store_true',\n",
    "                          help='force rebuild the documentation from the database')\n",
    "    document.add_argument('-s', '--sync', action='store_true',\n",
    "                          help='synchronise analyst changes to the database')\n",
    "\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help(sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    # Create new environment mode\n",
    "    ##############################\n",
    "    if args.mode == 'create':\n",
    "        if not args.location or args.location == '.':\n",
    "            config_file = create_environment(Path.cwd())\n",
    "        elif args.location[0] == '/':\n",
    "            config_file = create_environment(Path(args.location))\n",
    "        else:\n",
    "            config_file = create_environment((Path.cwd() / args.location))\n",
    "\n",
    "        sys.exit()\n",
    "\n",
    "    ##############################\n",
    "    # Use environment modes\n",
    "    ##############################\n",
    "    config_file = args.config_file\n",
    "    env = DataIntakeEnv(config_file)\n",
    "\n",
    "    # Register mode\n",
    "    ##############################\n",
    "    if args.mode == 'register':\n",
    "        if args.force:\n",
    "            if input(\n",
    "                    \"!!! WARNING --force is a DESTRUCTIVE action, system information for specified dataset will be overwritten.\\nIf no data groups are specified that means ALL data groups.\\n\\nAre you sure you want to continue? (Y/N)\") == \"Y\":\n",
    "                print(\"Activating forced recalculation\")\n",
    "                env.force_recalculate = True\n",
    "            else:\n",
    "                print(\"Proceeding without force, registering new data only.\")\n",
    "\n",
    "        # TODO add data group and data group type specific registration calls\n",
    "\n",
    "        register_all(env)\n",
    "        sys.exit()\n",
    "\n",
    "    # Verify mode\n",
    "    ##############################\n",
    "    if args.mode == 'verify':\n",
    "        if args.deep:\n",
    "            [check_datagroup(env, group_type, light=False) for group_type in [dm.Delivery, dm.Raw_Data, dm.Dataset]]\n",
    "        else:\n",
    "            [check_datagroup(env, group_type) for group_type in [dm.Delivery, dm.Raw_Data, dm.Dataset]]\n",
    "        sys.exit()\n",
    "\n",
    "    # Generate docs mode\n",
    "    ##############################\n",
    "    if args.mode == 'document':\n",
    "        if args.force:\n",
    "            if input(\n",
    "                    \"!!! WARNING --force is a DESTRUCTIVE action, documentation will be overwritten.\\nIf no data groups are specified that means ALL data groups.\\n\\nAre you sure you want to continue? (Y/N)\") == \"Y\":\n",
    "                print(\"Activating forced documentation rebuild\")\n",
    "                env.force_rebuild = True\n",
    "            else:\n",
    "                print(\"Proceeding without force, synchronising data and rebuilding.\")\n",
    "        if args.sync:\n",
    "            [sync_data_folder(env, group_type) for group_type in [dm.Delivery, dm.Raw_Data, dm.Dataset]]\n",
    "        sys.exit()\n",
    "\n",
    "    # Clean up mode\n",
    "    #############################\n",
    "    if args.mode == 'clean':\n",
    "        print(\"TBD: will allow you to purge the database if there are registered data groups that need to be removed.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     sys.exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-updating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drt",
   "language": "python",
   "name": "drt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
