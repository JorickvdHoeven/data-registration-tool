{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-accountability",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# hide \n",
    "#default_exp cli\n",
    "#default_cls_lvl 3\n",
    "from nbdev import *\n",
    "from drt.cli import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "from drt.environment import DataIntakeEnv\n",
    "from drt.create_environment import create_environment\n",
    "from drt.registration import register_all\n",
    "from drt.verification import check_datagroup\n",
    "from drt.receipt import sync_data_folder\n",
    "import drt.data_model as dm\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys\n",
    "import typer \n",
    "import types\n",
    "\n",
    "app = typer.Typer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-messaging",
   "metadata": {},
   "source": [
    "# Command line functions\n",
    "\n",
    "> Below the functions used to call the applicaitons are defined. Functions are grouped into a few main areas, `create`, `register`, `verify`, `document`, `clean` these different areas allow you to perform actions in those domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@app.command()\n",
    "def create(location:str ='.'):\n",
    "    \"\"\"\n",
    "    create a new data registration area\n",
    "    \"\"\"\n",
    "    if not location or location == '.':\n",
    "        config_file = create_environment(Path.cwd())\n",
    "    elif location[0] == '/':\n",
    "        config_file = create_environment(Path(location))\n",
    "    else:\n",
    "        config_file = create_environment((Path.cwd() / location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@app.command()\n",
    "def register(config_file:Path = '.config/config.ini', force:bool = False):\n",
    "    \"\"\"\n",
    "    register any new data elements, run with --force to regeister existing data elements\n",
    "    \"\"\"\n",
    "    env = DataIntakeEnv(config_file)\n",
    "    if force:\n",
    "        if input(\n",
    "                \"!!! WARNING --force is a DESTRUCTIVE action, system information for specified dataset will be overwritten.\\nIf no data groups are specified that means ALL data groups.\\n\\nAre you sure you want to continue? (Y/N)\") == \"Y\":\n",
    "            print(\"Activating forced recalculation\")\n",
    "            env.force_recalculate = True\n",
    "        else:\n",
    "            print(\"Proceeding without force, registering new data only.\")\n",
    "\n",
    "    # TODO add data group and data group type specific registration calls\n",
    "\n",
    "    register_all(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@app.command()\n",
    "def verify(config_file:Path = \".config/config.ini\", calc_hash:bool = False):\n",
    "    \"\"\"\n",
    "    verify the data registration environment to determine if there are data elements which need remediating. \n",
    "    i.e. there is data missing, a report missing, or a script missing. \n",
    "    this will also check the meta data of the files in the file system against the recorded metadata. If your\n",
    "    data isn't too big, run this with --calc_hash to activate hash verification.\n",
    "    \"\"\"\n",
    "    env = DataIntakeEnv(config_file)\n",
    "    if calc_hash:\n",
    "        [check_datagroup(env, group_type, light=False) for group_type in [dm.Delivery, dm.Raw_Data, dm.Dataset]]\n",
    "    else:\n",
    "        [check_datagroup(env, group_type) for group_type in [dm.Delivery, dm.Raw_Data, dm.Dataset]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@app.command()\n",
    "def document(config_file:Path = './config/config.ini', force:bool = False, sync:bool =True):\n",
    "    \"\"\"\n",
    "    Build documentation based on information in db and provided by analysts\n",
    "    \"\"\"\n",
    "    env = DataIntakeEnv(config_file)\n",
    "    if force:\n",
    "        if input(\n",
    "                \"!!! WARNING --force is a DESTRUCTIVE action, documentation will be overwritten.\\nIf no data groups are specified that means ALL data groups.\\n\\nAre you sure you want to continue? (Y/N)\") == \"Y\":\n",
    "            print(\"Activating forced documentation rebuild\")\n",
    "            env.force_rebuild = True\n",
    "        else:\n",
    "            print(\"Proceeding without force, synchronising data and rebuilding.\")\n",
    "    if sync:\n",
    "        [sync_data_folder(env, group_type) for group_type in [dm.Delivery, dm.Raw_Data, dm.Dataset]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def main():\n",
    "    app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_cli.ipynb.\n",
      "Converted 02_create_environment.ipynb.\n",
      "Converted 03_data_model.ipynb.\n",
      "Converted 04_environment.ipynb.\n",
      "Converted 05_receipt.ipynb.\n",
      "Converted 06_registration.ipynb.\n",
      "Converted 07_verification.ipynb.\n",
      "Converted 99_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-reaction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drt",
   "language": "python",
   "name": "drt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
