{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-payday",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "#default_exp registration\n",
    "#default_cls_lvl 3\n",
    "from nbdev import *\n",
    "from drt.registration import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-hammer",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from re import L\n",
    "from drt.environment import DataIntakeEnv\n",
    "import drt.utils as utils\n",
    "import drt.receipt as rct\n",
    "import itertools\n",
    "import drt.data_model as dm\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from drt.utils import Data_Groups_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-corporation",
   "metadata": {},
   "source": [
    "# Registration\n",
    "\n",
    "> Register new data elements added to the system by the analyst\n",
    "\n",
    "Module to contain all data registration code. If other methods need to be used\n",
    "this module will call out to them such as utility functions to gather folder\n",
    "metadata or document generation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def extract_delivery_from_script(env:DataIntakeEnv, folder:Path) -> str:\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    [summary]\n",
    "\n",
    "    ##### Parameters\n",
    "    env : DataIntakeEnv\n",
    "        [description]\n",
    "        \n",
    "    folder : Path\n",
    "        [description]\n",
    "        \n",
    "\n",
    "    ##### Returns\n",
    "    str\n",
    "        [description]\n",
    "\n",
    "    \"\"\"\n",
    "    # load script data\n",
    "    # get all registered delivery names\n",
    "    # search for delivery names in script\n",
    "    # return the delivery name which is the source\n",
    "    # error if there is more than one source\n",
    "\n",
    "    files = [fil for fil in folder.rglob(\"*\") \n",
    "             if fil.suffix[1:] in env.script_extension_list\n",
    "                and fil.is_file()\n",
    "    ]\n",
    "\n",
    "    text = ''\n",
    "\n",
    "    for fil in files:\n",
    "        with open(fil, mode='rt') as f:\n",
    "            text = text + f.read()\n",
    "\n",
    "    sources = []\n",
    "    for delivery in env.session.query(dm.Delivery).all():\n",
    "        if delivery.name in text:\n",
    "            sources.append(delivery)\n",
    "    \n",
    "    if len(sources) > 1:\n",
    "        print(f\"[!!] Error loading source for {folder}, too many sources\" )\n",
    "        return None\n",
    "    elif len(sources) == 0:\n",
    "        print(f\"[!!] Error no registered source found for {folder}\")\n",
    "        return None\n",
    "    else:\n",
    "        return sources[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def register_data_group(env:DataIntakeEnv, folder:Path, group_type: Data_Groups_Type, record: Data_Groups_Type = None):\n",
    "    \"\"\"\n",
    "    Register a single data group to the database.\n",
    "\n",
    "    ##### Parameters\n",
    "    env : DataIntakeEnv\n",
    "        The application environment settings.\n",
    "        \n",
    "    folder : Path\n",
    "        The full path to the folder of the data group to register. Relative paths won't work.\n",
    "        \n",
    "    group_type : str\n",
    "        The group type to put it in the proper table.\n",
    "        \n",
    "    record : dm.Data_Group, optional\n",
    "        If this is a pre-existing record and you have it provide it here, by default None\n",
    "\n",
    "    ##### Raises\n",
    "    TypeError\n",
    "        group_type must be one of ['delivery', 'raw_data', 'dataset']\n",
    "\n",
    "    \"\"\"\n",
    "    dg = group_type\n",
    "    if not record:\n",
    "        record = env.session.query(dg).filter_by(name = folder.name).first()\n",
    "    \n",
    "    try:\n",
    "        data = utils.process_data_group(folder, dg)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[!] {folder} not processed, empty or non-existent\")\n",
    "        return False\n",
    "\n",
    "    if group_type == dm.Raw_Data or type(record) == dm.Raw_Data:\n",
    "        raw_data_source = extract_delivery_from_script(env, folder)\n",
    "\n",
    "    # Set the system fields based on the metadata collected\n",
    "    if record: \n",
    "        # we have an existing record create it\n",
    "        dg = record\n",
    "        dg.type = data['type']\n",
    "        dg.name = data['name']\n",
    "        dg.last_update = data['last_update']\n",
    "        dg.size = data['size']\n",
    "        dg.num_files = data['num_files']\n",
    "        dg.group_hash= data['group_hash']\n",
    "        dg.group_last_modified= data['group_last_modified']\n",
    "        if type(record) == dm.Raw_Data:\n",
    "            dg.source = raw_data_source\n",
    "    # we need to create a new record\n",
    "    elif group_type == dm.Delivery:\n",
    "        dg = dm.Delivery(**data)\n",
    "        env.session.add(dg)\n",
    "    elif group_type == dm.Raw_Data:\n",
    "        dg =dm.Raw_Data(**data, source=raw_data_source)\n",
    "        env.session.add(dg)\n",
    "    elif group_type == dm.Dataset:\n",
    "        dg = dm.Dataset(**data)\n",
    "        env.session.add(dg)\n",
    "    else:\n",
    "        raise TypeError\n",
    "\n",
    "    env.session.commit()\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def register_data_folder(env:DataIntakeEnv, group_type: Data_Groups_Type, force:bool = False):\n",
    "    \"\"\"\n",
    "    Scans a folder containing data groups and registers them if they\n",
    "    don't already exist in the database. \n",
    "\n",
    "    ##### Parameters\n",
    "    env : DataIntakeEnv\n",
    "        The environment with data intake process pathnames.\n",
    "        \n",
    "    group_type : str\n",
    "        The type of folder to scan, delivery, raw_data, or dataset.\n",
    "\n",
    "    force : bool, optional\n",
    "        If we force we ignore the current data and regenerate all stats. This will\n",
    "        overwrite previous stats.\n",
    "\n",
    "    ##### Raises\n",
    "    ValueError\n",
    "        The right type must be passed. \n",
    "\n",
    "    \"\"\"\n",
    "    # get folder list, if not delivery folder then skip \"In_Progress_*\"\n",
    "    if group_type == dm.Delivery:\n",
    "        root_folder = env.delivery_folder\n",
    "        folder_list = [fil\n",
    "                       for fil in root_folder.iterdir()\n",
    "                       if fil.is_dir() and not fil.name.startswith(\".\")]\n",
    "\n",
    "\n",
    "    elif group_type == dm.Raw_Data:\n",
    "        root_folder = env.raw_data_folder\n",
    "        folder_list = [fil\n",
    "                       for fil in root_folder.iterdir()\n",
    "                       if not (fil.name.startswith(\".\") or fil.name.startswith(\"In_Progress\"))\n",
    "                       and fil.is_dir()]\n",
    "\n",
    "    elif group_type == dm.Dataset: # group_type == 3\n",
    "        root_folder = env.dataset_folder\n",
    "        folder_list = [fil\n",
    "                       for fil in root_folder.iterdir()\n",
    "                       if not (fil.name.startswith(\".\") or fil.name.startswith(\"In_Progress\"))\n",
    "                       and fil.is_dir()]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    # Process new folders and add them to the database. \n",
    "    data_group_list = env.get_data_group_list(group_type)\n",
    "    known_folders = [ item.name for item in data_group_list ]\n",
    "    new_folders = list(set([f.name for f in folder_list]) - set(known_folders))\n",
    "    \n",
    "    process_folders = list(zip(new_folders, itertools.repeat(None)))\n",
    "    if force:\n",
    "        process_folders.extend([(item.name, item) for item in data_group_list if (root_folder / item.name).is_dir()])\n",
    "\n",
    "    for folder, record in process_folders:\n",
    "        folder = root_folder / folder\n",
    "        registered = register_data_group(env, folder, group_type, record)\n",
    "        if force:\n",
    "            rct.write_receipt(env, folder)\n",
    "        elif registered:\n",
    "            rct.sync_data_group(env, folder)\n",
    "            rct.write_receipt(env, folder)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def register_all(env:DataIntakeEnv):\n",
    "    \"\"\"\n",
    "    Register all new data groups in the data intake process environment.\n",
    "    This on purpose, ignores In_Progress and . files. \n",
    "\n",
    "    ##### Parameters\n",
    "    env : DataIntakeEnv\n",
    "        The data intake process environment to scan and register new data groups.\n",
    "        \n",
    "    \"\"\"\n",
    "    [ register_data_folder(env, i, env.force_recalculate) for i in [dm.Delivery, dm.Raw_Data, dm.Dataset] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-rocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_cli.ipynb.\n",
      "Converted 02_create_environment.ipynb.\n",
      "Converted 03_data_model.ipynb.\n",
      "Converted 04_environment.ipynb.\n",
      "Converted 05_receipt.ipynb.\n",
      "Converted 06_registration.ipynb.\n",
      "Converted 07_verification.ipynb.\n",
      "Converted 99_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drt",
   "language": "python",
   "name": "drt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
